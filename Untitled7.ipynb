import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.utils.data as data_utils
from torch.autograd import Variable
import sklearn
from sklearn.preprocessing import StandardScaler
from tqdm.notebook import trange, tqdm
import os

from pyflo import system
from pyflo.nrcs import hydrology
uh484 = system.array_from_csv('deep_bucket_lab/distributions/scs484.csv')

g = 1.271e8
time_step = 1
rain_probability_range = {"None": [0.3, 0.4],
                          "Light": [0.4, 0.5],
                          "Heavy": [0.1, 0.3]}

threshold_precip = 0.01 # precip value boundary between "light" and "heavy"
max_precip = 0.25 # max amount of precip possible

# distribution parameters
rain_depth_range = {"Light": [0.0008108, 0.0009759], "Heavy": [0.2341, 0.0101, 0.009250]}
bucket_attributes_range = {"A_bucket": [5e2, 2e3],
                           "H_bucket": [0.1, 0.3],
                           "rA_spigot": [0.1, 0.2], # calculations to be a function of H_bucket
                           "rH_spigot": [0.05, 0.15], # calculations to be a function of H_bucket
                           ### The following two parameters come from standard distributions based on real data.
                           # Do not change these:
                           "K_infiltration": [-13.8857, 1.1835], # location and scale of normal distribution
                           "ET_parameter": [2.2447, 9.9807e-5, 0.0016], # shape, loc, and scale of Weibull min dist

                           "soil_depth": [0.3, 0.8]
                          }
bucket_attributes_list = list(bucket_attributes_range.keys())
bucket_attributes_list.append('A_spigot')
bucket_attributes_list.append('H_spigot')
bucket_attributes_lstm_inputs = ['H_bucket', 'rA_spigot', 'rH_spigot', 'soil_depth']
print("LSTM model input attributes", bucket_attributes_lstm_inputs)
input_vars = ['precip', 'et', 'h_bucket']
input_vars.extend(bucket_attributes_lstm_inputs)
output_vars = ['q_total', 'q_overflow', 'q_spigot']
n_input = len(input_vars)
n_output = len(output_vars)

noise = {"pet": 0.1, "et": 0.1, "q": 0.1, "head": 0.1}
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Using CUDA device:", torch.cuda.get_device_name(0))
elif torch.backends.mps.is_available():
    device = torch.device("mps")
    print("Using Apple M3/M2/M1 (Metal) device")
else:
    device = 'cpu'
    print("Using CPU")
hidden_state_size = 128
num_layers = 1
num_epochs = 1
batch_size = 128
seq_length = 336
learning_rate = np.linspace(start=0.001, stop=0.0001, num=num_epochs)

n_buckets_split = {"train": 20, "val": 10,"test": 1}
time_splits = {"warmup":256, "train": 1032, "val": 1032,"test": 1032}


num_records = time_splits["warmup"] + time_splits["train"] + time_splits["val"] + time_splits["test"] + seq_length * 3
n_buckets = n_buckets_split["train"] + n_buckets_split["val"] + n_buckets_split["test"]

def split_parameters():
    # create lists of bucket indices for each set based on the given bucket splits
    buckets_for_training = list(range(0, n_buckets_split['train'] + 1))
    buckets_for_val = list(range(n_buckets_split['train'] + 1,
                                 n_buckets_split['train'] + n_buckets_split['val'] + 1))
    buckets_for_test = list(range(n_buckets - n_buckets_split['test'], n_buckets))

    # determine the time range for each set based on the given time splits
    train_start = time_splits["warmup"] + seq_length
    train_end   = time_splits["warmup"] + time_splits["train"]
    val_start   = train_end + seq_length
    val_end     = val_start + time_splits["val"]
    test_start  = val_end + seq_length
    test_end    = test_start + time_splits["test"]

    # organize the split parameters into separate lists for each set
    train_split_parameters = [buckets_for_training, train_start, train_end]
    val_split_parameters = [buckets_for_val, val_start, val_end]
    test_split_parameters = [buckets_for_test, test_start, test_end]

    return [train_split_parameters, val_split_parameters, test_split_parameters]

[[buckets_for_training, train_start, train_end],
[buckets_for_val, val_start, val_end],
[buckets_for_test, test_start, test_end]]= split_parameters()

def setup_buckets(n_buckets):
    # Boundary conditions
    buckets = {bucket_attribute:[] for bucket_attribute in bucket_attributes_list}
    buckets['A_spigot'] = []
    buckets['H_spigot'] = []
    for i in range(n_buckets):
        for attribute in bucket_attributes_list:
            if attribute == 'A_bucket' or attribute == 'H_bucket' or attribute == 'rA_spigot' or attribute == 'rH_spigot' or attribute == 'soil_depth':
                buckets[attribute].append(np.random.uniform(bucket_attributes_range[attribute][0],
                                                        bucket_attributes_range[attribute][1]))
            if attribute == 'K_infiltration':
                buckets[attribute].append(np.random.normal(bucket_attributes_range[attribute][0],
                                                        bucket_attributes_range[attribute][1]))

            if attribute == "ET_parameter":
                buckets[attribute].append(stats.weibull_min.rvs(bucket_attributes_range[attribute][0],
                                                                bucket_attributes_range[attribute][1],
                                                                bucket_attributes_range[attribute][2]))

        buckets['A_spigot'].append(np.pi * (0.5 * buckets['H_bucket'][i] * buckets['rA_spigot'][i]) ** 2)
        buckets['H_spigot'].append(buckets['H_bucket'][i] * buckets['rH_spigot'][i])

    # Initial conditions
    h_water_level = [np.random.uniform(0, buckets["H_bucket"][i]) for i in range(n_buckets)]
    mass_overflow = [0]*n_buckets

    return buckets, h_water_level, mass_overflow

buckets, h_water_level, mass_overflow = setup_buckets(n_buckets)

def pick_rain_params():
    buck_rain_params = [rain_depth_range,
                        np.random.uniform(rain_probability_range["None"][0],
                                            rain_probability_range["None"][1]),
                        np.random.uniform(rain_probability_range["Heavy"][0],
                                            rain_probability_range["Heavy"][1]),
                        np.random.uniform(rain_probability_range["Light"][0],
                                            rain_probability_range["Light"][1])
                 ]
    return buck_rain_params

def random_rain(preceding_rain, bucket_rain_params):
    depth_range, no_rain_probability, light_rain_probability, heavy_rain_probability = bucket_rain_params
    # some percent of time we have no rain at all
    if np.random.uniform(0.01, 0.99) < no_rain_probability:
        rain = 0

    # When we do have rain, the probability of heavy or light rain depends on the previous hour's rainfall
    else:
        rain = np.inf
        # If last hour was a light rainy hour, or no rain, then we are likely to have light rain this hour
        if preceding_rain < threshold_precip:
            if np.random.uniform(0.0, 1.0) < light_rain_probability:
                while rain < 0 or rain > threshold_precip:
                    rain = stats.gumbel_r.rvs(depth_range["Light"][0], depth_range["Light"][1])
            else:
                # But if we do have heavy rain, then it could be very heavy
                while rain < threshold_precip or rain > max_precip:
                    rain = stats.genpareto.rvs(depth_range["Heavy"][0], depth_range["Heavy"][1], depth_range["Heavy"][2])

        # If it was heavy rain last hour, then we might have heavy rain again this hour
        else:
            if np.random.uniform(0.0, 1.0) < heavy_rain_probability:
                while rain < threshold_precip or rain > max_precip:
                    rain = stats.genpareto.rvs(depth_range["Heavy"][0], depth_range["Heavy"][1], depth_range["Heavy"][2])
            else:
                while rain < 0 or rain > threshold_precip:
                    rain = stats.gumbel_r.rvs(depth_range["Light"][0], depth_range["Light"][1])
    return rain

in_list = {}
for ibuc in range(n_buckets):
    bucket_rain_params = pick_rain_params()
    in_list[ibuc] = [0]
    for i in range(1, num_records):
        in_list[ibuc].append(random_rain(in_list[ibuc][i-1], bucket_rain_params))

def apply_unit_hydrograph(df, ibuc):
    """Given a bucket‐simulation DataFrame with 'q_overflow' and 'q_spigot' (both in m/s normalized by area),
    compute and append a 'q_total' column by routing combined runoff through a unit hydrograph.
    """
    # build the Basin object
    area_acres = buckets["A_bucket"][ibuc] / 4047
    basin = hydrology.Basin(
        area       = area_acres,
        cn         = 83.0,
        tc         = 2.3,
        runoff_dist= uh484,
        peak_factor= 1
    )

    # prepare cumulative‐inch input
    n = len(df)
    q_in = np.zeros((n, 2))
    cum_inches = 0.0
    for i in range(n):
        cum_inches += (df.loc[i,'q_overflow'] + df.loc[i,'q_spigot']) * 39.3701
        q_in[i] = (i, cum_inches)

    # run UH
    full = basin.flood_hydrograph(q_in, interval=1)[:,1]

    # trim or pad to match df length
    if len(full) >= n:
        out = full[:n]
    else:
        out = np.pad(full, (0, n-len(full)), 'constant')

    # convert back to m per time step, normalized by area
    df['q_total'] = out / 35.315 / buckets["A_bucket"][ibuc] * 3600

    return df

def run_bucket_simulation(ibuc):
    columns = ['precip', 'et', 'infiltration', 'h_bucket', 'q_overflow', 'q_spigot', 'q_total']
    columns.extend(bucket_attributes_list)
    # Memory to store model results
    df = pd.DataFrame(index=list(range(len(in_list[ibuc]))), columns=columns)

    # Main loop through time
    for t, precip_in in enumerate(in_list[ibuc]):

        # Add the input mass to the bucket
        h_water_level[ibuc] = h_water_level[ibuc] + precip_in

        # Lose mass out of the bucket. Some periodic type loss, evaporation, and some infiltration...

        # ET (m/s) is the value at each time step taking diurnal fluctuations into account. The definite integral of the following function
        # (excluding noise) from 0 to 24 is equal to ET_parameter, which is measured in m/day.
        et = np.max([0, ((1/7.6394)* buckets["ET_parameter"][ibuc]) * np.sin((np.pi / 12)*t) * np.random.normal(1, noise['pet'])])

        k = 10 ** buckets['K_infiltration'][ibuc]
        L = buckets['soil_depth'][ibuc]

        # Calculate infiltration using Darcy's Law: Q = (k * ρ * g * A * Δh) / (μ * L) → infiltration = Q / A
        # Final form: infiltration = (k * ρ * g * Δh) / (μ * L), with Δh = soil depth + water level height
        delta_h = h_water_level[ibuc] + L
        infiltration = k * delta_h / L

        h_water_level[ibuc] = np.max([0 , (h_water_level[ibuc] - et)])
        h_water_level[ibuc] = np.max([0 , (h_water_level[ibuc] - infiltration)])
        h_water_level[ibuc] = h_water_level[ibuc] * np.random.normal(1, noise['et'])

        # Overflow if the bucket is too full
        if h_water_level[ibuc] > buckets["H_bucket"][ibuc]:
            mass_overflow[ibuc] = h_water_level[ibuc] - buckets["H_bucket"][ibuc]
            h_water_level[ibuc] = buckets["H_bucket"][ibuc]
            h_water_level[ibuc] = h_water_level[ibuc] - np.random.uniform(0, noise['q'])

        # Calculate head on the spigot
        h_head_over_spigot = (h_water_level[ibuc] - buckets["H_spigot"][ibuc] )
        h_head_over_spigot = h_head_over_spigot * np.random.normal(1, noise['head'])

        # Calculate water leaving bucket through spigot
        if h_head_over_spigot > 0:
            velocity_out = np.sqrt(2 * g * h_head_over_spigot)
            spigot_out_volume = velocity_out *  buckets["A_spigot"][ibuc] * time_step

            # prevents spigot from draining water below H_spigot
            spigot_out = np.min([spigot_out_volume / buckets["A_bucket"][ibuc], h_head_over_spigot])
            h_water_level[ibuc] -= spigot_out
        else:
            spigot_out = 0

        # Save the data in time series
        df.loc[t,'precip'] = precip_in
        df.loc[t,'et'] = et
        df.loc[t,'infiltration'] = infiltration
        df.loc[t,'h_bucket'] = h_water_level[ibuc]
        df.loc[t,'q_overflow'] = mass_overflow[ibuc]
        df.loc[t,'q_spigot'] = spigot_out
        for attribute in bucket_attributes_list:
            df.loc[t, attribute] = buckets[attribute][ibuc]

        mass_overflow[ibuc] = 0

    # --- route through unit hydrograph ---
    df = apply_unit_hydrograph(df, ibuc)

    # ---- mass tracking columns ----
    # all in meters of water per time step, per unit area
    df['cum_precip']   = df['precip'].cumsum()
    df['cum_et']       = df['et'].cumsum()
    df['cum_inf']      = df['infiltration'].cumsum()
    df['cum_runoff']   = df['q_overflow'].cumsum() + df['q_spigot'].cumsum()
    df['storage']      = df['h_bucket']
    df['mass_out_tot'] = df['cum_et'] + df['cum_inf'] + df['cum_runoff'] + df['storage']
    df['residual_frac']= (df['cum_precip'] - df['mass_out_tot']) / df['cum_precip']
    # --------------------------------

    return df

bucket_dictionary = {}

# Define the progress milestones
milestones = [0.2, 0.4, 0.6, 0.8, 1.0]
n_buckets_completed = 0  # Counter for completed buckets

for ibuc in range(n_buckets):
    bucket_dictionary[ibuc] = run_bucket_simulation(ibuc)

    # Increment the completed bucket counter
    n_buckets_completed += 1

    # Calculate the current progress as a fraction
    progress = n_buckets_completed / n_buckets

    # Check if we have reached any of the milestones
    for milestone in milestones:
        if progress >= milestone:
            print(f"Progress: {int(milestone * 100)}% complete.")
            milestones.remove(milestone)  # Remove the milestone once it is reached
            break  # To avoid printing multiple milestones at once

# =========================================
# MODIFIED LSTM CLASS WITH PERSISTENT STATE
# =========================================
class PersistentLSTM(nn.Module):
    def __init__(self, num_classes, input_size, hidden_size, num_layers, batch_size, seq_length):
        super(PersistentLSTM, self).__init__()
        self.num_classes = num_classes
        self.num_layers = num_layers
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.seq_length = seq_length
        self.batch_size = batch_size

        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, 
                           num_layers=num_layers, batch_first=True)
        self.relu = nn.ReLU()
        self.fc_1 = nn.Linear(hidden_size, num_classes)
        self.hidden = None

    def forward(self, x, init_states=None):
        if init_states is not None:
            self.hidden = init_states
        
        out, self.hidden = self.lstm(x, self.hidden)
        out = self.relu(out)
        prediction = self.fc_1(out)
        prediction = self.relu(prediction)
        return prediction

    def init_hidden(self, batch_size=1, device='cpu'):
        self.hidden = (
            torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),
            torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)
        )

    def detach_hidden(self):
        if self.hidden is not None:
            self.hidden = tuple(h.detach() for h in self.hidden)

    def save_hidden(self, filename):
        if self.hidden is not None:
            torch.save(self.hidden, filename)

    def load_hidden(self, filename):
        if os.path.exists(filename):
            self.hidden = torch.load(filename, map_location=device)
        else:
            self.init_hidden(device=device)

# Original LSTM class (for comparison)
class LSTM1(nn.Module):
    def __init__(self, num_classes, input_size, hidden_size, num_layers, batch_size, seq_length):
        super(LSTM1, self).__init__()
        self.num_classes = num_classes
        self.num_layers = num_layers
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.seq_length = seq_length
        self.batch_size = batch_size

        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)
        self.relu = nn.ReLU()
        self.fc_1 = nn.Linear(hidden_size, num_classes)

    def forward(self, x, init_states=None):
        if init_states is None:
            h_t = Variable(torch.zeros(1, x.size(0), self.hidden_size, device=x.device))
            c_t = Variable(torch.zeros(1, x.size(0), self.hidden_size, device=x.device))
            init_states = (h_t, c_t)

        out, _ = self.lstm(x, init_states)
        out = self.relu(out)
        prediction = self.fc_1(out)
        prediction = self.relu(prediction)
        return prediction

# =========================================
# MODIFIED TRAINING FUNCTIONS
# =========================================
def train_original_model(lstm, train_loader, buckets_for_training):
    """Original training approach with state reset each batch"""
    criterion = nn.MSELoss()
    optimizer = optim.Adam(lstm.parameters(), lr=learning_rate[0])
    epoch_bar = tqdm(range(num_epochs), desc="Original Training", position=0, total=num_epochs)
    results = {ibuc: {"loss": [], "RMSE": []} for ibuc in buckets_for_training}

    for epoch in epoch_bar:
        epoch_loss = 0
        epoch_rmse = 0
        batch_count = 0
        
        for ibuc in buckets_for_training:
            batch_bar = tqdm(
                train_loader[ibuc],
                desc=f"Bucket: {ibuc}, Epoch: {epoch}",
                position=1, leave=False, disable=True
            )

            for data, targets in batch_bar:
                data, targets = data.to(device), targets.to(device)
                optimizer.zero_grad()

                out = lstm(data)
                preds = out[:, -1:, :]  # last timestep
                true = targets[:, -1:, :]
                loss = criterion(preds, true)
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                epoch_rmse += loss.sqrt().item()
                batch_count += 1

                batch_bar.set_postfix(
                    loss=f"{loss.item():.4f}",
                    RMSE=f"{loss.sqrt().item():.2f}"
                )

        avg_loss = epoch_loss / batch_count
        avg_rmse = epoch_rmse / batch_count
        
        # Store results for all buckets (simplified)
        for ibuc in buckets_for_training:
            results[ibuc]["loss"].append(avg_loss)
            results[ibuc]["RMSE"].append(avg_rmse)

        epoch_bar.set_postfix(
            loss=f"{avg_loss:.4f}",
            RMSE=f"{avg_rmse:.2f}"
        )
        print(f"Epoch {epoch} - Loss: {avg_loss:.4f}, RMSE: {avg_rmse:.4f}")

    return lstm, results


def train_persistent_model(model, train_loader, buckets_for_training):
    """Persistent training with proper dynamic batch size handling"""
    model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=learning_rate[0])
    criterion = nn.MSELoss()
    
    epoch_bar = tqdm(range(num_epochs), desc="Persistent Training", position=0, total=num_epochs)
    results = {ibuc: {"loss": [], "RMSE": []} for ibuc in buckets_for_training}

    for epoch in range(num_epochs):
        # Start with no hidden state - we'll initialize with first batch
        model.hidden = None
        
        epoch_loss = 0
        epoch_rmse = 0
        batch_count = 0
        
        for ibuc in buckets_for_training:
            for batch_idx, (data, targets) in enumerate(train_loader[ibuc]):
                data, targets = data.to(device), targets.to(device)
                current_batch_size = data.size(0)  # Get actual batch size
                
                # 🔥 CRITICAL FIX: Handle hidden state initialization
                if model.hidden is None:
                    # First batch - initialize with correct size
                    model.init_hidden(batch_size=current_batch_size, device=device)
                else:
                    # Subsequent batches - check if we need to resize
                    prev_batch_size = model.hidden[0].size(1)
                    if prev_batch_size != current_batch_size:
                        # Resize hidden state to match current batch size
                        model.hidden = (
                            model.hidden[0][:, :current_batch_size, :].contiguous(),
                            model.hidden[1][:, :current_batch_size, :].contiguous()
                        )
                
                optimizer.zero_grad()

                # Forward pass with current hidden state
                out = model(data)
                
                preds = out[:, -1:, :]
                true = targets[:, -1:, :]
                loss = criterion(preds, true)
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                epoch_rmse += loss.sqrt().item()
                batch_count += 1

                # Detach hidden state for next batch
                model.detach_hidden()

                if batch_idx % 10 == 0:  # Progress update
                    print(f"Epoch {epoch}, Bucket {ibuc}, Batch {batch_idx}: Loss = {loss.item():.4f}")

        if batch_count > 0:
            avg_loss = epoch_loss / batch_count
            avg_rmse = epoch_rmse / batch_count
        else:
            avg_loss = 0
            avg_rmse = 0
        
        for ibuc in buckets_for_training:
            results[ibuc]["loss"].append(avg_loss)
            results[ibuc]["RMSE"].append(avg_rmse)

        epoch_bar.set_postfix(
            loss=f"{avg_loss:.4f}",
            RMSE=f"{avg_rmse:.2f}"
        )
        epoch_bar.update(1)
        print(f"Epoch {epoch} - Loss: {avg_loss:.4f}, RMSE: {avg_rmse:.4f}")

    return model, results

# =========================================
# MODIFIED EVALUATION FUNCTIONS
# =========================================
def check_validation_period_comparison(lstm_original, lstm_persistent, np_val_seq_X, ibuc, n_plot=100):
    """Compare both models on validation period"""
    
    def __make_prediction(lstm_model, model_type="original"):
        if model_type == "persistent":
            lstm_model.init_hidden(batch_size=1, device=device)
            
        lstm_output_val = lstm_model(torch.Tensor(np_val_seq_X[ibuc]).to(device=device))
        val_predictions = {var: [] for var in output_vars}

        for i in range(lstm_output_val.shape[0]):
            for j, var in enumerate(output_vars):
                val_predictions[var].append((lstm_output_val[i, -1, j].cpu().detach().numpy() * \
                                             np.std(df.loc[train_start:train_end, var])) + \
                                            np.mean(df.loc[train_start:train_end, var]))
        return val_predictions

    def __compute_nse(val_predictions):
        nse_values = {}
        for var in output_vars:
            actual_values = df.loc[val_start:val_end, var]
            mean_actual = np.mean(actual_values)
            pred_variance = 0
            obs_variance = 0

            for i, pred in enumerate(val_predictions[var]):
                t = i + seq_length - 1
                pred_variance += np.power((pred - actual_values.values[t]), 2)
                obs_variance += np.power((mean_actual - actual_values.values[t]), 2)

            nse_values[var] = np.round(1 - (pred_variance / obs_variance), 4)
        return nse_values

    df = bucket_dictionary[ibuc]
    
    # Get predictions from both models
    original_predictions = __make_prediction(lstm_original, "original")
    persistent_predictions = __make_prediction(lstm_persistent, "persistent")
    
    # Compute NSE for both models
    original_nse = __compute_nse(original_predictions)
    persistent_nse = __compute_nse(persistent_predictions)
    
    print(f"\n=== COMPARISON FOR BUCKET {ibuc} ===")
    print("Nash-Sutcliffe Efficiency (NSE):")
    for var in output_vars:
        print(f"  {var}:")
        print(f"    Original:    {original_nse[var]}")
        print(f"    Persistent:  {persistent_nse[var]}")
        print(f"    Difference:  {persistent_nse[var] - original_nse[var]:.4f}")

    # Plot comparisons
    fig, axes = plt.subplots(len(output_vars), 1, figsize=(15, 5*len(output_vars)))
    if len(output_vars) == 1:
        axes = [axes]

    for ax, var in zip(axes, output_vars):
        obs_start = val_start + seq_length
        obs_end = obs_start + n_plot - 1
        
        actual_values = df.loc[obs_start:obs_end, var].values
        ax.plot(actual_values, 'k-', label='Actual', linewidth=2, alpha=0.8)
        ax.plot(original_predictions[var][:n_plot], 'r--', label='Original LSTM', alpha=0.8)
        ax.plot(persistent_predictions[var][:n_plot], 'b--', label='Persistent LSTM', alpha=0.8)
        
        ax.set_title(f'{var} - Prediction Comparison\n'
                    f'Original NSE: {original_nse[var]}, Persistent NSE: {persistent_nse[var]}')
        ax.set_xlabel('Time Step')
        ax.set_ylabel(var)
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()
    
    return original_nse, persistent_nse

def compare_learning_curves(original_results, persistent_results, buckets_for_training):
    """Compare learning curves of both approaches"""
    # Original model metrics
    orig_losses = np.stack([original_results[b]['loss'] for b in buckets_for_training])
    orig_rmses = np.stack([original_results[b]['RMSE'] for b in buckets_for_training])
    
    # Persistent model metrics  
    persist_losses = np.stack([persistent_results[b]['loss'] for b in buckets_for_training])
    persist_rmses = np.stack([persistent_results[b]['RMSE'] for b in buckets_for_training])
    
    epochs = np.arange(orig_losses.shape[1])
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Loss comparison
    ax1.plot(epochs, orig_losses.mean(axis=0), 'r-', label='Original LSTM', linewidth=2)
    ax1.plot(epochs, persist_losses.mean(axis=0), 'b-', label='Persistent LSTM', linewidth=2)
    ax1.fill_between(epochs, 
                    np.percentile(orig_losses, 25, axis=0),
                    np.percentile(orig_losses, 75, axis=0), 
                    color='red', alpha=0.2)
    ax1.fill_between(epochs,
                    np.percentile(persist_losses, 25, axis=0),
                    np.percentile(persist_losses, 75, axis=0),
                    color='blue', alpha=0.2)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training Loss Comparison')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # RMSE comparison
    ax2.plot(epochs, orig_rmses.mean(axis=0), 'r-', label='Original LSTM', linewidth=2)
    ax2.plot(epochs, persist_rmses.mean(axis=0), 'b-', label='Persistent LSTM', linewidth=2)
    ax2.fill_between(epochs,
                    np.percentile(orig_rmses, 25, axis=0),
                    np.percentile(orig_rmses, 75, axis=0),
                    color='red', alpha=0.2)
    ax2.fill_between(epochs,
                    np.percentile(persist_rmses, 25, axis=0),
                    np.percentile(persist_rmses, 75, axis=0),
                    color='blue', alpha=0.2)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('RMSE')
    ax2.set_title('Training RMSE Comparison')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Print final performance comparison
    print("\n=== FINAL PERFORMANCE COMPARISON ===")
    print(f"Original LSTM - Final Loss: {orig_losses.mean(axis=0)[-1]:.4f}, Final RMSE: {orig_rmses.mean(axis=0)[-1]:.4f}")
    print(f"Persistent LSTM - Final Loss: {persist_losses.mean(axis=0)[-1]:.4f}, Final RMSE: {persist_rmses.mean(axis=0)[-1]:.4f}")
    
    loss_improvement = ((orig_losses.mean(axis=0)[-1] - persist_losses.mean(axis=0)[-1]) / orig_losses.mean(axis=0)[-1]) * 100
    rmse_improvement = ((orig_rmses.mean(axis=0)[-1] - persist_rmses.mean(axis=0)[-1]) / orig_rmses.mean(axis=0)[-1]) * 100
    
    print(f"Loss Improvement: {loss_improvement:+.2f}%")
    print(f"RMSE Improvement: {rmse_improvement:+.2f}%")

# =========================================
# MAIN EXECUTION WITH BOTH APPROACHES
# =========================================
torch.manual_seed(1)

# Initialize both models
lstm_original = LSTM1(num_classes=n_output,
                     input_size=n_input,
                     hidden_size=hidden_state_size,
                     num_layers=num_layers,
                     batch_size=batch_size,
                     seq_length=seq_length).to(device=device)

lstm_persistent = PersistentLSTM(num_classes=n_output,
                               input_size=n_input,
                               hidden_size=hidden_state_size,
                               num_layers=num_layers,
                               batch_size=batch_size,
                               seq_length=seq_length).to(device=device)

# Fit scalers
def fit_scaler():
    frames = [bucket_dictionary[ibuc].loc[train_start:train_end, input_vars] for ibuc in buckets_for_training]
    df_in = pd.concat(frames)
    scaler_in = StandardScaler()
    _ = scaler_in.fit_transform(df_in)

    frames = [bucket_dictionary[ibuc].loc[train_start:train_end, output_vars] for ibuc in buckets_for_training]
    df_out = pd.concat(frames)
    scaler_out = StandardScaler()
    _ = scaler_out.fit_transform(df_out)
    return scaler_in, scaler_out

scaler_in, scaler_out = fit_scaler()

# Create data loaders
k_preds = 1

# Replace your make_data_loader function with this:
def make_data_loader(start, end, bucket_list):
    """Data loader that ensures consistent batch sizes by dropping incomplete batches"""
    loader = {}
    np_seq_X = {}
    np_seq_y = {}

    for ibuc in bucket_list:
        df = bucket_dictionary[ibuc]
        # scale inputs and outputs
        Xin = scaler_in.transform(df.loc[start:end, input_vars])
        Yin = scaler_out.transform(df.loc[start:end, output_vars])

        # number of samples: full window length = seq_length + k_preds
        n_total = Xin.shape[0]
        n_samples = n_total - seq_length + 1

        # allocate arrays
        X = np.zeros((n_samples, seq_length, n_input))
        Y = np.zeros((n_samples, seq_length, n_output))

        for i in range(n_samples):
            t0 = i + seq_length
            X[i] = Xin[i:t0]
            Y[i] = Yin[i:t0]

        np_seq_X[ibuc] = X
        np_seq_y[ibuc] = Y

        ds = torch.utils.data.TensorDataset(
            torch.Tensor(X),
            torch.Tensor(Y)
        )
        # 🔥 KEY FIX: drop_last=True ensures all batches have exactly batch_size samples
        loader[ibuc] = torch.utils.data.DataLoader(
            ds, 
            batch_size=batch_size, 
            shuffle=True,
            drop_last=True  # This drops the last incomplete batch
        )

    return loader, np_seq_X, np_seq_y

# Use this consistent data loader
train_loader, np_train_seq_X, np_train_seq_y = make_data_loader(train_start, train_end, buckets_for_training)
val_loader, np_val_seq_X, np_val_seq_y = make_data_loader(val_start, val_end, buckets_for_val)
test_loader, np_test_seq_X, np_test_seq_y = make_data_loader(test_start, test_end, buckets_for_test)

print("\n" + "="*60)
print("TRAINING ORIGINAL LSTM MODEL")
print("="*60)
lstm_original, original_results = train_original_model(lstm_original, train_loader, buckets_for_training)

print("\n" + "="*60)
print("TRAINING PERSISTENT LSTM MODEL")
print("="*60)
lstm_persistent, persistent_results = train_persistent_model(lstm_persistent, train_loader, buckets_for_training)

# Compare learning curves
print("\n" + "="*60)
print("COMPARING LEARNING CURVES")
print("="*60)
compare_learning_curves(original_results, persistent_results, buckets_for_training)

# Compare validation performance
print("\n" + "="*60)
print("COMPARING VALIDATION PERFORMANCE")
print("="*60)
all_original_nse = []
all_persistent_nse = []

for ibuc in buckets_for_val[:3]:  # Compare on first 3 validation buckets
    original_nse, persistent_nse = check_validation_period_comparison(
        lstm_original, lstm_persistent, np_val_seq_X, ibuc
    )
    all_original_nse.append(original_nse)
    all_persistent_nse.append(persistent_nse)

# Final summary
print("\n" + "="*60)
print("FINAL SUMMARY")
print("="*60)
print("Average NSE across validation buckets:")
for var in output_vars:
    orig_avg = np.mean([nse[var] for nse in all_original_nse])
    persist_avg = np.mean([nse[var] for nse in all_persistent_nse])
    improvement = persist_avg - orig_avg
    print(f"{var}:")
    print(f"  Original:    {orig_avg:.4f}")
    print(f"  Persistent:  {persist_avg:.4f}")
    print(f"  Improvement: {improvement:+.4f} ({improvement/orig_avg*100:+.1f}%)")
